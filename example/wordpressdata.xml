<?xml version="1.0" encoding="UTF-8" ?>
<!-- This is a WordPress eXtended RSS file generated by WordPress as an export of your site. -->
<!-- It contains information about your site's posts, pages, comments, categories, and other content. -->
<!-- You may use this file to transfer that content from one site to another. -->
<!-- This file is not intended to serve as a complete backup of your site. -->

<!-- To import this information into a WordPress site follow these steps: -->
<!-- 1. Log in to that site as an administrator. -->
<!-- 2. Go to Tools: Import in the WordPress admin panel. -->
<!-- 3. Install the "WordPress" importer from the list. -->
<!-- 4. Activate & Run Importer. -->
<!-- 5. Upload this file using the form provided on that page. -->
<!-- 6. You will first be asked to map the authors in this export file to users -->
<!--    on the site. For each author, you may choose to map to an -->
<!--    existing user on the site or to create a new user. -->
<!-- 7. WordPress will then import each of the posts, pages, comments, categories, etc. -->
<!--    contained in this file into your site. -->

<!-- generator="WordPress/4.8.8" created="2019-01-04 19:04" -->
<rss version="2.0"
	xmlns:excerpt="http://wordpress.org/export/1.2/excerpt/"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:wp="http://wordpress.org/export/1.2/"
>

<channel>
	<title>E:Programmer</title>
	<link>http://alexoglou.webpages.auth.gr/wordpress</link>
	<description>e: entrepreneurial</description>
	<pubDate>Fri, 04 Jan 2019 19:04:45 +0000</pubDate>
	<language>en-US</language>
	<wp:wxr_version>1.2</wp:wxr_version>
	<wp:base_site_url>http://alexoglou.webpages.auth.gr/wordpress</wp:base_site_url>
	<wp:base_blog_url>http://alexoglou.webpages.auth.gr/wordpress</wp:base_blog_url>

	<wp:author><wp:author_id>1</wp:author_id><wp:author_login><![CDATA[alexoglou]]></wp:author_login><wp:author_email><![CDATA[alexoglou@ece.auth.gr]]></wp:author_email><wp:author_display_name><![CDATA[Kostas Alexoglou]]></wp:author_display_name><wp:author_first_name><![CDATA[]]></wp:author_first_name><wp:author_last_name><![CDATA[]]></wp:author_last_name></wp:author>
	<wp:author><wp:author_id>2</wp:author_id><wp:author_login><![CDATA[Jason]]></wp:author_login><wp:author_email><![CDATA[iaswnparaskev@gmail.com]]></wp:author_email><wp:author_display_name><![CDATA[Iasonas Paraskevopoulos]]></wp:author_display_name><wp:author_first_name><![CDATA[Iasonas]]></wp:author_first_name><wp:author_last_name><![CDATA[Paraskevopoulos]]></wp:author_last_name></wp:author>


	<generator>https://wordpress.org/?v=4.8.8</generator>
    
	<item>
		<title>Brute Forcing Forms with Scrapy</title>
		<link>http://alexoglou.webpages.auth.gr/wordpress/?p=14</link>
		<pubDate>Mon, 28 Aug 2017 20:42:23 +0000</pubDate>
		<dc:creator><![CDATA[alexoglou]]></dc:creator>
		<guid isPermaLink="false">http://alexoglou.webpages.auth.gr/wordpress/?p=14</guid>
		<description></description>
		<content:encoded><![CDATA[I recently had the opportunity for me and my team to attend WebSummit as a startup. And if you don't already know Web Summit gives you a great opportunity with the Alpha package to get 3 people of your team for a very low price.

And then as a team of 8 I decided to send them and request one more of this package, leading to a discount per ticket only for Alpha exhibitors for a short of time. Annnnd I missed the deadline.  Then I tried to find every possible way to find a discount and get my whole team to the biggest tech event in the world.

As I could see from the WebSummit ticket service the coupon check worked like this. You typed your code and hitting submit and Ajax request was generated and then an Ajax response was coming. That's is nice. And no security like csrf tokens in my way.

The request was like this
<blockquote>https://ti.to/websummit/2017-web-summit/iframe?discount_code=LTSW12343l&amp;release_ids=398oawcyg90&amp;398oawcyg90=1&amp;source=,</blockquote>
so it is easy for me to make different "ajax" requests with unique codes and get my response back.

As a response I was getting a json object with html code inside the view tag. The keyword for detecting if the coupon was right was the absense of  the keyword "unavailable" . So now let's break it down and start bruteforcing.
<h3>Get your hands dirty</h3>
Start with creating a virtual environment and installing Scrapy and Django with pip .
<pre class="lang:default decode:true" title="terminal">mkvirtualenv -p python3 ScrapyBruteForce
cd Desktop/
mkdir ScrapyBruteForce
pip install scrapy
pip install django
cd ScrapyBruteForce
</pre>
&nbsp;

I installed django as this post is only for educational reasons. And we should never ever try to hack anything.<img class="size-medium wp-image-19 aligncenter" src="http://alexoglou.webpages.auth.gr/wordpress/wp-content/uploads/2017/08/giphy-300x180.gif" alt="" width="300" height="180" />

&nbsp;
<h3><strong>Django Server Creation</strong></h3>
&nbsp;

Now you will ask me why django. To simulate the ajax calls we show earlier at Web Summit ticket service. If you are familiar with django skip this part of feel free to clone my <a href="https://github.com/konsalex/BruteForceWithScrapy">GitHub</a> repo. And start playing now. Or go directly to the <a href="#unique-identifier">scrapy part</a>.

For anyone familiar with Ajax and Django this is going to be just a few lines of code. Just creating a simple form with input the coupon and when the submit button is pressed an ajax call will be triggered. If the response is positive we will not have the keyword "unavailable" in our tag.

Now to begin we have to initialise a django project .
<pre class="lang:default decode:true" title="terminal">django-admin startproject WebSummitTicketing
cd WebSummitTicketing/
django-admin startapp Bruteforce</pre>
And now your django project should be like this.
<pre class="tab-convert:true lang:default decode:true " title="Dir tree">.
├── Bruteforce
│     ├── __init__.py
│     ├── admin.py
│     ├── apps.py
│     ├── migrations
│     │&amp;nbsp;&amp;nbsp; └── __init__.py
│     ├── models.py
│     ├── tests.py
│     └── views.py
├── WebSummitTicketing
│     ├── __init__.py
│     ├── settings.py
│     ├── urls.py
│     └── wsgi.py
└── manage.py
</pre>
&nbsp;
<p class="p1">Django is a MVC framework so we have to define a url for our index.html first and then a url for the ajax calls.</p>
So open urls.py with yout favourite text editor and fill urlpatterns with the following and then open views.py to handle the view process.
<pre class="lang:python decode:true" title="urls.py">urlpatterns = [
    url(r'^admin/', admin.site.urls),
    url(r'^$', views.home, name='home'),
    url(r'^ajax/coupon/', views.ajax, name='ajax'),
]</pre>
<pre class="lang:default decode:true" title="views.py">from django.shortcuts import render,redirect

def home(request):
    return render(request,'index.html')</pre>
Now in order for django to find that index.html file we have to import first, our Bruteforce app in the settings.py. It should look now like this
<pre class="lang:default decode:true" title="settings.py">INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'Bruteforce'
]</pre>
And we have to create a folder inside Bruteforce dir with the name templates.This is were django will look for our html files. Now create inside that folder the index.html file.

&nbsp;

Inside that html place this code .
<pre class="lang:default decode:true" title="index.html">&lt;!Doctype html&gt;
&lt;html lang="en"&gt;
    &lt;head&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;form&gt;
            {% csrf_token %}
            &lt;input id="coupon" type="text" name="coupon" method="POST"&gt;
            &lt;button id="submit"&gt;
        &lt;/form&gt;
        &lt;script
        src="https://code.jquery.com/jquery-1.12.4.min.js"
        integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ="
        crossorigin="anonymous"&gt;&lt;/script&gt;
        
        &lt;script&gt;
        $("#submit").click(function() {
            
            var form = $(this).closest("form");
        
            $.ajax({
                type: "POST",
                url: '/ajax/coupon/',
                data: form.serialize(),
                dataType: 'json',
                success: function (data) {
                console.log(data.success)
        }});
        
        
        });
        &lt;/script&gt;
    &lt;/body&gt;
&lt;/html&gt;</pre>
Remember without CSRF token django will not let you make an Ajax request. And I don't  blame it. Web safety is one of the #1 priorities nowadays .

Now as we saw earlier we got the response as html code inside json key "view". But now we are going to get the response in json format with the key success for the sake of simplicity.

Before we start penetrating one more step. We have to write the view function to handle the ajax requests.
<pre class="lang:default decode:true" title="views.py">def ajax(request):

    code=request.GET.get('code',None)

    if code=="LWFD12334m":
        data = {
            'sucess': 'available'
        }
    else:
        data={
        'success':'unavailable'
        }
    
    return JsonResponse(data)

</pre>
As we can see from the code we are getting a request to our server in this format http://localhost:8000/ajax/coupon/?code=******** . So we extract the code value and check if it is the right code. If it is the right one it should return a json object with the key success with the value available if the code is the right one or the key success with the value unavailable if the code isn't the right one.

Now run the server and in another terminal make a request to see the response.
<pre class="lang:default decode:true" title="terminal">python manage.py runserver

#### In another terminal #####

curl http://localhost:8000/ajax/coupon/?code=LWFD1234m

curl http://localhost:8000/ajax/coupon/?code=WFAS2412w</pre>
With the first request you should get a response
<p class="p1"><span class="s1">{"sucess": "available"} while with the second request you should get </span></p>
<p class="p1"><span class="s1">{"sucess": "unavailable"} as a response. So we are now ready to start writing our penetration script and get that coupon code we always wanted. </span></p>
I am also curious to find out if my <strong id="unique-identifier"></strong>assumption was right and Scrapy was one of the finest solutions to my problem. To check it I will right a simple python script to make the requests as I want and the I will implement it with a Scrapy spider and compare the results.
<h3><strong>Scrapy pen tool</strong></h3>
Now stop the server if it is still running and go to the root of the project and initialize your scrapy project . Then go inside the spider folder and create a file named PenTool.py .
<pre class="lang:default decode:true" title="Terminal">scrapy startproject PenTool
cd PenTool/PenTool/spiders/ &amp;&amp; touch PenTool.py
</pre>
And your projects tree should look like it
<pre class="lang:default decode:true" title="Dir tree">.
├── PenTool
│   ├── __init__.py
│   ├── __pycache__
│   ├── items.py
│   ├── middlewares.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders
│       ├── PenTool.py
│       ├── __init__.py
│       └── __pycache__
└── scrapy.cfg</pre>
&nbsp;

Open your PenTool.py and start writing our little bruteforcing spider.
<pre class="lang:default decode:true" title="PenTool.py">import string 
import scrapy
from itertools import combinations
from scrapy.exceptions import CloseSpider

class Myspider(scrapy.Spider):
    
    name = "WebSummit"

    def start_requests(self):


            for x in combinations(string.ascii_uppercase,3) :

                up=(''.join(x))

                for y in combinations(string.digits,5) :

                    dig=(''.join(y))


                    for z in string.ascii_lowercase :


                        low=(''.join(z))


                        url= "http://127.0.0.1:8000/ajax/coupon/?code=LWFD1234m"

                        
                        yield scrapy.Request(url=url, callback=self.parse)

                    
        
    def parse(self, response):


        if "unavailable" in response.text :

            return

        else :

            raise CloseSpider('Code Found : {}' .format(response.url))</pre>
&nbsp;

As we saw in the beginning of the Article the coupon had a format of 4 upper case letters 5 digits in a row and then a lower case letter. That means 26^4x10^5x26 = 1.1881376e+12 . Those are a lot of combinations. Now we can estimate the worst case scenario. Modifying a little bit the code to run a "speed" test I saw that Scrapy requests on local host handled <span class="s1">1000 requests in : 6.962241301999711 seconds. </span>Not bad. Not bad at all.  That means 142.85 requests per second or 0.0069622413 seconds per request . For our case that would mean 82721006711.788118282336 seconds or 265.95 years to complete.

With python request library that time fell to 4.8seconds. And I am starting to thinking that scrapy lost the battle with the localhost server. But that's it?

I tempted and tested it in real environment just for 1000 requests.  With the request library the results were absolutely horrible. Like a lot of minutes to complete not even worth of waiting. Then I tested with Scrapy and the results were <span class="s1">15.752997165000124 seconds for 1000 requests . That's what I wanted to see, Scrapy win this battle with ease.</span>

The results are that bad with urllib also. If you wanna get your hands dirtier giving a try at  asyncio library could save you more time. As <a href="https://pawelmhm.github.io/asyncio/python/aiohttp/2016/04/22/asyncio-aiohttp.html">Paweł Miech</a> wrote in his article with asyncio Python can achieve around 111 111 in one minute comparing with Scrapy that achieved around 4000 requests per minute in WebSummit's server.

Using Scrapy as a web crawler only is like turn around in the pretty nice features it has about handling requests concurrent without us getting dirty.  And Bruteforcing is one of them.

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>14</wp:post_id>
		<wp:post_date><![CDATA[2017-08-28 20:42:23]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2017-08-28 20:42:23]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[brute-forcing-forms-withs-scrapy]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[dsq_thread_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[6105885619]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_primary_category]]></wp:meta_key>
			<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_focuskw_text_input]]></wp:meta_key>
			<wp:meta_value><![CDATA[Bruteforce with scrapy]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_focuskw]]></wp:meta_key>
			<wp:meta_value><![CDATA[Bruteforce with scrapy]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_title]]></wp:meta_key>
			<wp:meta_value><![CDATA[Bruteforce with Scrapy]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_metadesc]]></wp:meta_key>
			<wp:meta_value><![CDATA[Get advantage of Scrapy HTTP request concurrent handling and penetrate a website.]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_linkdex]]></wp:meta_key>
			<wp:meta_value><![CDATA[58]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_content_score]]></wp:meta_key>
			<wp:meta_value><![CDATA[90]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[medium_post]]></wp:meta_key>
			<wp:meta_value><![CDATA[O:11:"Medium_Post":11:{s:16:"author_image_url";s:65:"https://cdn-images-1.medium.com/fit/c/400/400/0*FOfPFiI2etdGKf3W.";s:10:"author_url";s:35:"https://medium.com/@costa.alexoglou";s:11:"byline_name";N;s:12:"byline_email";N;s:10:"cross_link";s:2:"no";s:2:"id";s:12:"85cf6f39fea8";s:21:"follower_notification";s:3:"yes";s:7:"license";s:19:"all-rights-reserved";s:14:"publication_id";s:2:"-1";s:6:"status";s:6:"public";s:3:"url";s:80:"https://medium.com/@costa.alexoglou/brute-forcing-forms-with-scrapy-85cf6f39fea8";}]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_oembed_289e27aa451b6f86b0fc30b19fb40424]]></wp:meta_key>
			<wp:meta_value><![CDATA[{{unknown}}]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_oembed_0edb9cb03845508595b5e92f50fa3783]]></wp:meta_key>
			<wp:meta_value><![CDATA[{{unknown}}]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_oembed_1a2039bdb31ff3565d06b6f1d5c64af6]]></wp:meta_key>
			<wp:meta_value><![CDATA[{{unknown}}]]></wp:meta_value>
		</wp:postmeta>
	</item>
	<item>
		<title>A simple blink detector using a small convolutional neural network with Python</title>
		<link>http://alexoglou.webpages.auth.gr/wordpress/?p=65</link>
		<pubDate>Mon, 02 Oct 2017 11:05:36 +0000</pubDate>
		<dc:creator><![CDATA[Jason]]></dc:creator>
		<guid isPermaLink="false">http://alexoglou.webpages.auth.gr/wordpress/?p=65</guid>
		<description></description>
		<content:encoded><![CDATA[Today we are going to develop a computer vision application for detecting if the eyes are open or close and count blinks. To achieve our goal we are going to train a small convolutional neural network (CNN) with Keras and then using OpenCV and dlib we 'll implement our blink detector .

The process of building our blink detector has two stages, first the training of the neural network and then the development of the detector. If you want you can skip stage one and go to stage two and use the network that we have already trained for you. You can find the code at my <a href="https://github.com/iparaskev/simple-blink-detector">github repo</a>.
<h3><strong>Stage one </strong></h3>
For these stage we 'll assume that you already know a fair bit about convolutional neural nets. That's because we won't talk about how cnn's work. If these is the first time you hear about cnn's then you can go straight to stage two. Stanford has a<a href="http://cs231n.github.io/"> great course</a> which will help you understand a lot about neural networks and cnn's .

To get started lets see what we need to train our cnn. We 'll use keras library with tensorflow backend, keras gives you the choise to use it with tensorflow or theano backend. Also you can use either python 2.7 or python 3.x . If you don't have keras or tensorflow at your system you can
<pre class="lang:sh decode:true">$ pip install --upgrade tensorflow</pre>
and
<pre class="lang:default decode:true">$ pip install keras</pre>
, tensorflow supports CUDA if you have CUDA-capable GPU but for these tutorial it won't make a huge difference.

So we are going to train a binary classifier between open and close eyes. To do this we 'll need a dataset to train our classifier. For closed eyes we will use cropped images of size 26x34 from the <a href="http://parnec.nuaa.edu.cn/xtan/data/ClosedEyeDatabases.html">Closed Eyes In The Wild (CEW)</a> dataset and for opened eyes we used a manually anotaded images. We are going to use only left eye images because our dataset is small and we want the cnn to be more accurate, to achieve that we flipped the right images when we were cropping the whole face images. The complete dataset contains 2874 images. You can find the dataset in at csv format in the train folder in my repo.

To get started we 'll import the necessary packages:
<pre class="lang:python decode:true">import csv
import numpy as np 
import keras 
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D,Flatten,Dense,Activation,Dropout,MaxPooling2D
from keras.activations import relu
from keras.optimizers import Adam</pre>
Now that we have imported everything we need to load the data from the dataset, to do that we are going to write a function
<pre class="tab-convert:true lang:default decode:true">def readCsv(path):

	with open(path,'r') as f:
		#read the scv file with the dictionary format 
		reader = csv.DictReader(f)
		rows = list(reader)

	#imgs is a numpy array with all the images
	#tgs is a numpy array with the tags of the images
	imgs = np.empty((len(list(rows)),height,width,1),dtype=np.uint8)
	tgs = np.empty((len(list(rows)),1))
		
	for row,i in zip(rows,range(len(rows))):
			
		#convert the list back to the image format
		img = row['image']
		img = img.strip('[').strip(']').split(', ')
		im = np.array(img,dtype=np.uint8)
		im = im.reshape((26,34))
		im = np.expand_dims(im, axis=2)
		imgs[i] = im

		#the tag for open is 1 and for close is 0
		tag = row['state']
		if tag == 'open':
			tgs[i] = 1
		else:
			tgs[i] = 0
	
	#shuffle the dataset
	index = np.random.permutation(imgs.shape[0])
	imgs = imgs[index]
	tgs = tgs[index]

	#return images and their respective tags
	return imgs,tgs</pre>
This function accepts a single required parameter, the path of the csv file with the dataset.

At first we read the csv file with the dictionary format and then we make a list with every row of the file. Then we make two empty numpy arrays to store the images and the tag of every image. After that we access through every row of the list, which contains an image and the image's tag , to assert to the previous arrays their values. In the end we shuffle the two arrays and we return them.

So to continue we are going to build our cnn using keras. Our network has three convolutional filters with relu activation, each filter followed by a max-pooling layer. Then we add dropout a dropout layer followed by two fully connected layers with relu activations also. Finally we add a single neuron with sigmoid activation for our binary classifier. As optimizer we 'll use adam and for our loss function we 'll use binary crossentropy.
<pre class="lang:default decode:true">#make the convolution neural network
def makeModel():
	model = Sequential()

	model.add(Conv2D(32, (3,3), padding = 'same',
                   input_shape=(height,width,1)))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2,2)))
	model.add(Conv2D(64, (2,2), padding= 'same'))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	model.add(Conv2D(128, (2,2), padding='same'))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	model.add(Dropout(0.25))

	model.add(Flatten())
	model.add(Dense(512))
	model.add(Activation('relu'))
	model.add(Dense(512))
	model.add(Activation('relu'))
	model.add(Dense(1))
	model.add(Activation('sigmoid'))

	
	model.compile(optimizer=Adam(lr=0.001), 
                      loss='binary_crossentropy',
                      metrics=['accuracy'])

	return model</pre>
Now we have all we need to train our small and simple cnn.
<pre class="lang:default decode:true">def main():

	xTrain ,yTrain = readCsv('dataset.csv')
	
	#scale the values of the images between 0 and 1
	xTrain = xTrain.astype('float32')
	xTrain /= 255

	model = makeModel()

	#do some data augmentation
	datagen = ImageDataGenerator(
        rotation_range=10,
        width_shift_range=0.2,
        height_shift_range=0.2,
        )
	datagen.fit(xTrain)

	#train the model
	model.fit_generator(datagen.flow(xTrain,yTrain,batch_size=32),
			    steps_per_epoch=len(xTrain) / 32, epochs=50)
	
	#save the model
	model.save('blinkModel.hdf5')</pre>
&nbsp;

First we load our images and the tags at two numpy arrays, then we scale the values of the images between 0 and 1, we do that because it makes the learning process faster. After that we do some data augmentation at our data to artificially increase the number of the training examples, because we have a small dataset and we have to reduce overfitting. Finally we train out network for 50 epochs with batch size of 32 and we save our trained cnn.

We know that normally we had to split our data at train, val and test sets, do some fine tuning and then train our network to evaluate it at our test set, but the purpose of this tutorial is to make fast a simple blink detector and not how to train a cnn classifier for open and close eyes. So to achieve that we don't give a lot of importance to really important steps of the training.
<h3 id="stage-two">Stage two</h3>
Now we have our trained cnn and we are ready  to build our blink detector.  Lets see what libraries we 'll need.
<pre class="lang:default decode:true ">import cv2
import dlib
import numpy as np
from keras.models import load_model
from scipy.spatial import distance as dist
from imutils import face_utils</pre>
The computer vision library we are going to use is OpenCV, if you don't have it you can install it following the instructions given <a href="https://www.pyimagesearch.com/2016/10/24/ubuntu-16-04-how-to-install-opencv/">here</a> for Ubuntu 16.04. Also we 'll use dlib and for a set of convenience functions to make working with OpenCV easier we 'll need to use imutils library. If you don't have any of those two installed on your system you can install them easily using
<pre class="lang:default decode:true ">$ pip install --upgrade imutils</pre>
and for dlib you can follow <a href="https://www.pyimagesearch.com/2017/03/27/how-to-install-dlib/">this guide</a> .

Overview of the detector: First we read each frame from the camera, then we crop the eyes and we give them to the cnn we have trained to make a prediction on them. After that we take the mean of the predictions because we look for blinks so we have to be sure. In the end we counter the consecutive close predictions and if they are more than a threshold we count it as a blink. Lets see some code.

Now we 'll define a function for face detection. We 'll use haarcascade's face detector because is faster than dlib's frontal face detector.
<pre class="lang:default decode:true ">face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')

# detect the face rectangle 
def detect(img, cascade = face_cascade , minimumFeatureSize=(20, 20)):
    if cascade.empty():
        raise (Exception("There was a problem loading your Haar Cascade xml file."))
    rects = cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=1, minSize=minimumFeatureSize)
    
    # if it doesn't return rectangle return array
    # with zero lenght
    if len(rects) == 0:
        return []

    #  convert last coord from (width,height) to (maxX, maxY)
    rects[:, 2:] += rects[:, :2]

    return rects</pre>
This function accepts a single required parameter the whole frame.

At <strong>first line</strong> we load the haarcascede classifier from the xml file, which you can find in the repo.

<strong>Lines 5-7 </strong>we check if the classifier has correctly loaded.

<strong>Lines 11-12 </strong>we check if the classifier hasn't find a rectangle with the face and return an empty list if it didn't.

Finally at <strong>line 15</strong> we convert the rectangle list from [x,y,a,b] where (x,y) are the coordinates of the left corner of the rectangle and a,b are the pixels we have to add to x and y respectively to form the whole rectangle, to [x,y,maxX,maxY]. Then we return the rectangle list which contains zero, one or more rectangles.

Now that we have find frame's rectangle  which contains the face, we can proceed to find the eyes.  Lets make a function for this.
<pre class="lang:default decode:true">predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")
def cropEyes(frame):
	 
	gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
	
	# detect the face at grayscale image
	te = detect(gray, minimumFeatureSize=(80, 80))

	# if the face detector doesn't detect face
	# return None, else if detects more than one faces
	# keep the bigger and if it is only one keep one dim
	if len(te) == 0:
		return None
	elif len(te) &gt; 1:
		face = te[0]
	elif len(te) == 1:
		[face] = te</pre>
Also these function accepts one required parameter the frame.

At <strong>line 1 </strong>we initialize the dlib's face predictor. You can learn more about it in <a href="https://www.pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/">this blog post</a>.

On <strong>line 4 </strong>we convert our frame to greyscale. Then on <strong>lines 6-17 </strong>we assign at te the value of the face detect function and then we check if it is empty and return none if it is, because we don't want the display of our predictor to stop(it will become more clear in a few minutes).
<pre class="lang:default decode:true"># keep the face region from the whole frame
	face_rect = dlib.rectangle(left = int(face[0]), top = int(face[1]),
								right = int(face[2]), bottom = int(face[3]))
	
	# determine the facial landmarks for the face region
	shape = predictor(gray, face_rect)
	shape = face_utils.shape_to_np(shape)

	#  grab the indexes of the facial landmarks for the left and
	#  right eye, respectively
	(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS["left_eye"]
	(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS["right_eye"]

	# extract the left and right eye coordinates
	leftEye = shape[lStart:lEnd]
	rightEye = shape[rStart:rEnd]</pre>
First we on <strong>line 2</strong> we take the face region from the whole frame and then we determine the facial landmarks for the face region, while <strong>line </strong><strong>5</strong> converts these coordinates to NumPy array.

<strong>Lines </strong><strong>11-12 </strong>we grab the indexes of the facial landmarks for the left and right eye from the full set of dlib's facial landmarks.

Next we extract the left and right eye coordinates using array slicing techniques using the indexes we just had grabbed.
<pre class="lang:default decode:true "># keep the upper and the lower limit of the eye 
	# and compute the height 
	l_uppery = min(leftEye[1:3,1])
	l_lowy = max(leftEye[4:,1])
	l_dify = abs(l_uppery - l_lowy)

	# compute the width of the eye
	lw = (leftEye[3][0] - leftEye[0][0])

	# we want the image for the cnn to be (26,34)
	# so we add the half of the difference at x and y
	# axis from the width at height respectively left-right
	# and up-down 
	minxl = (leftEye[0][0] - ((34-lw)/2))
	maxxl = (leftEye[3][0] + ((34-lw)/2)) 
	minyl = (l_uppery - ((26-l_dify)/2))
	maxyl = (l_lowy + ((26-l_dify)/2))
	
	# crop the eye rectangle from the frame
	left_eye_rect = np.rint([minxl, minyl, maxxl, maxyl])
	left_eye_rect = left_eye_rect.astype(int)
	left_eye_image = gray[(left_eye_rect[1]):left_eye_rect[3], (left_eye_rect[0]):left_eye_rect[2]]</pre>
Our cnn to be able to predict on an image, the image has to be the same format as the images which it trained with. So we need to make same adjustments at the eye coordinates we have.

First on <strong>lines 3-8 </strong>we find the minimum and maximum y value from our coordinates and we compute the height of the left eye. Dlib gives 6 pairs of coordinates for the eyes,

<img class="alignnone size-medium wp-image-79" src="http://alexoglou.webpages.auth.gr/wordpress/wp-content/uploads/2017/09/dlibpost-300x300.jpg" alt="" width="300" height="300" />

as you can see we want the minimum y from the second and third pair and the maximum y from the fifth and sixth to compute eye's height. The width is much easier because we simple have to take the x from the first and the fourth pair and compute their difference.

That is what we do at <strong>line 11.</strong>

Then on <strong>lines 17-21 </strong>to compute the coordinates of the eye's rectangle we add the half of the differences of the shape we want our image to be with the width and height of the eye we have to our x and y coordinates.

After at <strong>lines 24-26 </strong>we crop from the whole image the eye rectangle.

This was for the left eye, now we 'll do the same for the right.
<pre class="lang:default decode:true "># same as left eye at right eye
	r_uppery = min(rightEye[1:3,1])
	r_lowy = max(rightEye[4:,1])
	r_dify = abs(r_uppery - r_lowy)
	rw = (rightEye[3][0] - rightEye[0][0])
	minxr = (rightEye[0][0]-((34-rw)/2))
	maxxr = (rightEye[3][0] + ((34-rw)/2))
	minyr = (r_uppery - ((26-r_dify)/2))
	maxyr = (r_lowy + ((26-r_dify)/2))
	right_eye_rect = np.rint([minxr, minyr, maxxr, maxyr])
	right_eye_rect = right_eye_rect.astype(int)
	right_eye_image = gray[right_eye_rect[1]:right_eye_rect[3], right_eye_rect[0]:right_eye_rect[2]]</pre>
To finish our function
<pre class="lang:default decode:true "># if it doesn't detect left or right eye return None
	if 0 in left_eye_image.shape or 0 in right_eye_image.shape:
		return None
	# resize for the conv net
	left_eye_image = cv2.resize(left_eye_image, (34, 26))
	right_eye_image = cv2.resize(right_eye_image, (34, 26))
	right_eye_image = cv2.flip(right_eye_image, 1)
	# return left and right eye
	return left_eye_image, right_eye_image</pre>
we check if we haven't detect left or right eye so we can return none and if we have detected both of the eyes we resize them to be sure the images are the right size and we before we return the eye images we flip the right eye so we can have to left for right predictions.

Before we go to the main function of our script we 'll write a function for the rest preprocess of the every image we have to do for our cnn.
<pre class="lang:default decode:true "># make the image to have the same format as at training 
def cnnPreprocess(img):
	img = img.astype('float32')
	img /= 255
	img = np.expand_dims(img, axis=2)
	img = np.expand_dims(img, axis=0)
	return img</pre>
Here we scale the values of the images between 0 and 1 and we add two more dimensions because keras need the image to be of shape (rows,width,height,channels) where row are the number of the images, width and height of the images and channel the number of colors. So we have one image per time and 1 channel and that is what <strong>lines 5-6 </strong>do.

Finally we are ready for our main function.
<pre class="lang:default decode:true ">def main():
	# open the camera,load the cnn model 
	camera = cv2.VideoCapture(0)
	model = load_model('blinkModel.hdf5')
	
	# blinks is the number of total blinks ,close_counter
	# the counter for consecutive close predictions
	# and mem_counter the counter of the previous loop 
	close_counter = blinks = mem_counter= 0
	state = ''
	while True:
		
		ret, frame = camera.read()
		
		# detect eyes
		eyes = cropEyes(frame)
		if eyes is None:
			continue
		else:
			left_eye,right_eye = eyes
		
		# average the predictions of the two eyes 
		prediction = (model.predict(cnnPreprocess(left_eye)) + model.predict(cnnPreprocess(right_eye)))/2.0
</pre>
First we open our camera and we load our cnn model and we define some usable variable we 'll use and explain in a minute. Then we start reading consecutive frames.

At <strong>lines 16-19 </strong> we call our function for detecting and cropping the eyes from the whole frame and we check if the value of them is none. If it is none the script will stop so to avoid that we check for the value and we continue to the next loop if it is. After we just average our predictions for the eyes.
<pre class="lang:default decode:true "># blinks
		# if the eyes are open reset the counter for close eyes
		if prediction &gt; 0.5 :
			state = 'open'
			close_counter = 0
		else:
			state = 'close'
			close_counter += 1
		
		# if the eyes are open and previousle were closed
		# for sufficient number of frames then increcement 
		# the total blinks
		if state == 'open' and mem_counter &gt; 1:
			blinks += 1
		# keep the counter for the next loop 
		mem_counter = close_counter 

		# draw the total number of blinks on the frame along with
		# the state for the frame
		cv2.putText(frame, "Blinks: {}".format(blinks), (10, 30),
			cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
		cv2.putText(frame, "State: {}".format(state), (300, 30),
			cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
		
		# show the frame
		cv2.imshow('blinks counter', frame)
		key = cv2.waitKey(1) &amp; 0xFF

		# if the `q` key was pressed, break from the loop
		if key == ord('q'):
			break</pre>
&nbsp;

<strong>Lines 3-8 </strong>we check the value of the prediction if it is more than 0.5, because we have a binary classifier with a sigmoid neuron that gives as output the probability of an eye to be open and if it more than 50 % we classify it as open. If it is open we set the state variable open and the close_counter zero. if it close then we add one to the counter so we can know for how many consecutive frames the eyes were closed.

At <strong>lines 13-14 </strong>we see if the eyes are open and memory counter variable is more than one, memory counter has the value of the close counter of the previous loop. So we can check if the eyes are open and they were previously closed for sufficient frames. At this point you can adjust the number of consecutive frames at your camera.

Then we draw on our frame the number of total blinks and the current state.

Finally we display the frame and you can stop the counter pressing the button q.
<pre class="lang:default decode:true ">	# do a little clean up
	cv2.destroyAllWindows()
	del(camera)</pre>
And here we do a little clean up.

Now you have your blink detector. It was easy to built it and fast.You can use your own dataset if you want and you can change everything you want.

&nbsp;]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>65</wp:post_id>
		<wp:post_date><![CDATA[2017-10-02 11:05:36]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2017-10-02 11:05:36]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[blink_detector]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
		<category domain="category" nicename="computer-vision"><![CDATA[Computer Vision]]></category>
		<category domain="category" nicename="machine-learning"><![CDATA[Machine Learning]]></category>
		<wp:postmeta>
			<wp:meta_key><![CDATA[medium_post]]></wp:meta_key>
			<wp:meta_value><![CDATA[O:11:"Medium_Post":11:{s:16:"author_image_url";N;s:10:"author_url";N;s:11:"byline_name";N;s:12:"byline_email";N;s:10:"cross_link";N;s:2:"id";N;s:21:"follower_notification";N;s:7:"license";N;s:14:"publication_id";N;s:6:"status";N;s:3:"url";N;}]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
			<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_content_score]]></wp:meta_key>
			<wp:meta_value><![CDATA[30]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_primary_category]]></wp:meta_key>
			<wp:meta_value><![CDATA[12]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_focuskw_text_input]]></wp:meta_key>
			<wp:meta_value><![CDATA[Blink Detector]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_focuskw]]></wp:meta_key>
			<wp:meta_value><![CDATA[Blink Detector]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_linkdex]]></wp:meta_key>
			<wp:meta_value><![CDATA[76]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_title]]></wp:meta_key>
			<wp:meta_value><![CDATA[Blink Detector with Tensorflow]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[_yoast_wpseo_metadesc]]></wp:meta_key>
			<wp:meta_value><![CDATA[Building a blink detector with state of the art technologies and libraries like Keras, Tensorflow, dlib and OpenCV.]]></wp:meta_value>
		</wp:postmeta>
		<wp:postmeta>
			<wp:meta_key><![CDATA[dsq_thread_id]]></wp:meta_key>
			<wp:meta_value><![CDATA[6185412506]]></wp:meta_value>
		</wp:postmeta>
		<wp:comment>
			<wp:comment_id>1</wp:comment_id>
			<wp:comment_author><![CDATA[Shoaib Ahmed]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[shoaib.ahmedsk95@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[115.167.118.20]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2018-09-28 15:09:00]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2018-09-28 15:09:00]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Sir i have implemented the code and it works fine, but i cant get my state 'open', and my prediction value is [0.]. can you help me out please.???
Thanks]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[dsq_parent_post_id]]></wp:meta_key>
				<wp:meta_value><![CDATA[]]></wp:meta_value>
			</wp:commentmeta>
			<wp:commentmeta>
				<wp:meta_key><![CDATA[dsq_post_id]]></wp:meta_key>
				<wp:meta_value><![CDATA[4119036893]]></wp:meta_value>
			</wp:commentmeta>
		</wp:comment>
	</item>
</channel>
</rss>

<!-- Performance optimized by W3 Total Cache. Learn more: https://www.w3-edge.com/products/

 Served from: alexoglou.webpages.auth.gr @ 2019-01-04 19:04:45 by W3 Total Cache -->